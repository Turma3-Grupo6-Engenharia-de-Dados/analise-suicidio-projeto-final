{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ingestão dos dados da base DATAS_SUS"
      ],
      "metadata": {
        "id": "II4AwuFc8H8P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_25m6Hvad2t"
      },
      "outputs": [],
      "source": [
        "#1. Importação de bibliotecas\n",
        "!pip install --upgrade pysus\n",
        "import pandas as pd\n",
        "import pysus\n",
        "from pysus.online_data.SIM import download"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ano 2014"
      ],
      "metadata": {
        "id": "8nhjMtWx8cRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definição do ano e estados\n",
        "\n",
        "estados = [\"AC\", \"AL\", \"AP\", \"AM\", \"BA\", \"CE\", \"DF\", \"ES\", \"GO\", \"MA\", \"MT\", \"MS\", \"MG\", \"PA\", \"PB\", \"PR\", \"PE\", \"PI\", \"RJ\", \"RN\", \"RS\", \"RO\", \"RR\", \"SC\", \"SP\", \"SE\", \"TO\"]\n",
        "anos = [2014]\n",
        "\n",
        "# Baixa os dados\n",
        "parquet_set = download(groups=\"CID10\", states=estados, years=anos)\n",
        "\n",
        "# Converte cada arquivo em df e adiciona colunas de estado e ano\n",
        "list_of_dfs = []\n",
        "for estado, parquet in zip(estados, parquet_set):\n",
        "    df_estado = parquet.to_dataframe()\n",
        "    df_estado[\"ESTADO\"] = estado\n",
        "    df_estado[\"ANO\"] = 2014\n",
        "    list_of_dfs.append(df_estado)\n",
        "\n",
        "# Concatena (junta) tudo\n",
        "df = pd.concat(list_of_dfs, ignore_index=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q80Q8_Ww6sZp",
        "outputId": "4886bcd3-406a-404e-9dff-d2bc023de3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "785393it [00:00, 116192621.12it/s]    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtragem das colunas que não serão utilizadas\n",
        "Esta etapa foi feita antes de  colocar o df no bigquery devido ao tamanho da base de dados"
      ],
      "metadata": {
        "id": "94bPeGJu9Acc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleciona apenas as colunas desejadas\n",
        "df = df[[\"ESTADO\", \"ANO\", \"TIPOBITO\", \"IDADE\", \"SEXO\", \"RACACOR\",\"ESTCIV\", \"ESC2010\", \"LOCOCOR\", \"CAUSABAS\", \"CIRCOBITO\"]]\n",
        "\n",
        "# Salva o CSV filtrado\n",
        "df.to_csv(\"SIM_2014_filtrado.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"✅ CSV salvo apenas com as colunas selecionadas!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA5wu4ta7PNH",
        "outputId": "74900637-93d1-45c7-bb57-1b632d7c228d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV salvo apenas com as colunas selecionadas!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mFM9mhkXycXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ano 2015"
      ],
      "metadata": {
        "id": "lfzjjm3i_g28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definição do ano e estados\n",
        "\n",
        "estados = [\"AC\", \"AL\", \"AP\", \"AM\", \"BA\", \"CE\", \"DF\", \"ES\", \"GO\", \"MA\", \"MT\", \"MS\", \"MG\", \"PA\", \"PB\", \"PR\", \"PE\", \"PI\", \"RJ\", \"RN\", \"RS\", \"RO\", \"RR\", \"SC\", \"SP\", \"SE\", \"TO\"]\n",
        "anos = [2015]\n",
        "\n",
        "# Baixa os dados\n",
        "parquet_set = download(groups=\"CID10\", states=estados, years=anos)\n",
        "\n",
        "# Converte cada arquivo em df e adiciona colunas de estado e ano\n",
        "list_of_dfs = []\n",
        "for estado, parquet in zip(estados, parquet_set):\n",
        "    df_estado = parquet.to_dataframe()\n",
        "    df_estado[\"ESTADO\"] = estado\n",
        "    df_estado[\"ANO\"] = 2015\n",
        "    list_of_dfs.append(df_estado)\n",
        "\n",
        "# Concatena (junta) tudo\n",
        "df = pd.concat(list_of_dfs, ignore_index=True)\n",
        "print(\"✅ DF baixado com sucesso!!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d287e4cc-7f5e-4435-fdfd-98b42025b819",
        "id": "WCmwxmcn_g29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "750388it [00:00, 32422228.30it/s]     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtragem das colunas que não serão utilizadas\n",
        "Esta etapa foi feita antes de  colocar o df no bigquery devido ao tamanho da base de dados"
      ],
      "metadata": {
        "id": "c_2SkpW4_g29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleciona apenas as colunas desejadas\n",
        "df = df[[\"ESTADO\", \"ANO\", \"TIPOBITO\", \"IDADE\", \"SEXO\", \"RACACOR\",\"ESTCIV\", \"ESC2010\", \"LOCOCOR\", \"CAUSABAS\", \"CIRCOBITO\"]]\n",
        "\n",
        "# Salva o CSV filtrado\n",
        "df.to_csv(\"SIM_2015_filtrado.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"✅ CSV salvo apenas com as colunas selecionadas!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c91f3fa5-b0e8-4b56-d9de-385f9862ce79",
        "id": "CtkYKSbb_g2-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV salvo apenas com as colunas selecionadas!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mp9CZjMc_g2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ano 2016"
      ],
      "metadata": {
        "id": "vWBx6rR8CUAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definição do ano e estados\n",
        "\n",
        "estados = [\"AC\", \"AL\", \"AP\", \"AM\", \"BA\", \"CE\", \"DF\", \"ES\", \"GO\", \"MA\", \"MT\", \"MS\", \"MG\", \"PA\", \"PB\", \"PR\", \"PE\", \"PI\", \"RJ\", \"RN\", \"RS\", \"RO\", \"RR\", \"SC\", \"SP\", \"SE\", \"TO\"]\n",
        "anos = [2016]\n",
        "\n",
        "# Baixa os dados\n",
        "parquet_set = download(groups=\"CID10\", states=estados, years=anos)\n",
        "\n",
        "# Converte cada arquivo em df e adiciona colunas de estado e ano\n",
        "list_of_dfs = []\n",
        "for estado, parquet in zip(estados, parquet_set):\n",
        "    df_estado = parquet.to_dataframe()\n",
        "    df_estado[\"ESTADO\"] = estado\n",
        "    df_estado[\"ANO\"] = 2016\n",
        "    list_of_dfs.append(df_estado)\n",
        "\n",
        "# Concatena (junta) tudo\n",
        "df = pd.concat(list_of_dfs, ignore_index=True)\n",
        "print(\"✅ DF baixado com sucesso!!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "592ac465-4a83-402a-d457-4edcb67207dd",
        "id": "hp9yr6PaCUAn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DOTO2016.parquet: 100%|██████████| 31.3k/31.3k [00:01<00:00, 25.2kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DF baixado com sucesso!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtragem das colunas que não serão utilizadas\n",
        "Esta etapa foi feita antes de  colocar o df no bigquery devido ao tamanho da base de dados"
      ],
      "metadata": {
        "id": "fA6B1-n9CUAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleciona apenas as colunas desejadas\n",
        "df = df[[\"ESTADO\", \"ANO\", \"TIPOBITO\", \"IDADE\", \"SEXO\", \"RACACOR\",\"ESTCIV\", \"ESC2010\", \"LOCOCOR\", \"CAUSABAS\", \"CIRCOBITO\"]]\n",
        "\n",
        "# Salva o CSV filtrado\n",
        "df.to_csv(\"SIM_2016_filtrado.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"✅ CSV salvo apenas com as colunas selecionadas!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a333b383-7f62-4433-dec0-e3ff6363c934",
        "id": "olHofmjFCUAo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV salvo apenas com as colunas selecionadas!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8eCQ1-RPCUAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ano 2017"
      ],
      "metadata": {
        "id": "UxwcOPfgGKUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definição do ano e estados\n",
        "\n",
        "estados = [\"AC\", \"AL\", \"AP\", \"AM\", \"BA\", \"CE\", \"DF\", \"ES\", \"GO\", \"MA\", \"MT\", \"MS\", \"MG\", \"PA\", \"PB\", \"PR\", \"PE\", \"PI\", \"RJ\", \"RN\", \"RS\", \"RO\", \"RR\", \"SC\", \"SP\", \"SE\", \"TO\"]\n",
        "anos = [2017]\n",
        "\n",
        "# Baixa os dados\n",
        "parquet_set = download(groups=\"CID10\", states=estados, years=anos)\n",
        "\n",
        "# Converte cada arquivo em df e adiciona colunas de estado e ano\n",
        "list_of_dfs = []\n",
        "for estado, parquet in zip(estados, parquet_set):\n",
        "    df_estado = parquet.to_dataframe()\n",
        "    df_estado[\"ESTADO\"] = estado\n",
        "    df_estado[\"ANO\"] = 2017\n",
        "    list_of_dfs.append(df_estado)\n",
        "\n",
        "# Concatena (junta) tudo\n",
        "df = pd.concat(list_of_dfs, ignore_index=True)\n",
        "print(\"✅ DF baixado com sucesso!!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88ff9182-424e-47ad-8aa4-cf4ea45fa43f",
        "id": "9zSv_sdWGKUv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DOTO2017.parquet: 100%|██████████| 33.8k/33.8k [00:01<00:00, 18.9kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DF baixado com sucesso!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtragem das colunas que não serão utilizadas\n",
        "Esta etapa foi feita antes de  colocar o df no bigquery devido ao tamanho da base de dados"
      ],
      "metadata": {
        "id": "T_Vm9bkxGKUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleciona apenas as colunas desejadas\n",
        "df = df[[\"ESTADO\", \"ANO\", \"TIPOBITO\", \"IDADE\", \"SEXO\", \"RACACOR\",\"ESTCIV\", \"ESC2010\", \"LOCOCOR\", \"CAUSABAS\", \"CIRCOBITO\"]]\n",
        "\n",
        "# Salva o CSV filtrado\n",
        "df.to_csv(\"SIM_2017_filtrado.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"✅ CSV salvo apenas com as colunas selecionadas!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "168782c6-817e-4324-dc22-246ad20d02c0",
        "id": "D2YDzjNiGKUw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV salvo apenas com as colunas selecionadas!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ano 2018"
      ],
      "metadata": {
        "id": "Ir3iiH78GK1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definição do ano e estados\n",
        "\n",
        "estados = [\"AC\", \"AL\", \"AP\", \"AM\", \"BA\", \"CE\", \"DF\", \"ES\", \"GO\", \"MA\", \"MT\", \"MS\", \"MG\", \"PA\", \"PB\", \"PR\", \"PE\", \"PI\", \"RJ\", \"RN\", \"RS\", \"RO\", \"RR\", \"SC\", \"SP\", \"SE\", \"TO\"]\n",
        "anos = [2018]\n",
        "\n",
        "# Baixa os dados\n",
        "parquet_set = download(groups=\"CID10\", states=estados, years=anos)\n",
        "\n",
        "# Converte cada arquivo em df e adiciona colunas de estado e ano\n",
        "list_of_dfs = []\n",
        "for estado, parquet in zip(estados, parquet_set):\n",
        "    df_estado = parquet.to_dataframe()\n",
        "    df_estado[\"ESTADO\"] = estado\n",
        "    df_estado[\"ANO\"] = 2018\n",
        "    list_of_dfs.append(df_estado)\n",
        "\n",
        "# Concatena (junta) tudo\n",
        "df = pd.concat(list_of_dfs, ignore_index=True)\n",
        "print(\"✅ DF baixado com sucesso!!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20c2e735-ee26-4c54-e272-5d469e770aea",
        "id": "qAdT1ALqGK1N"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "659326it [00:00, 71553862.53it/s]     \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DF baixado com sucesso!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtragem das colunas que não serão utilizadas\n",
        "Esta etapa foi feita antes de  colocar o df no bigquery devido ao tamanho da base de dados"
      ],
      "metadata": {
        "id": "c0jMv7TzGK1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleciona apenas as colunas desejadas\n",
        "df = df[[\"ESTADO\", \"ANO\", \"TIPOBITO\", \"IDADE\", \"SEXO\", \"RACACOR\",\"ESTCIV\", \"ESC2010\", \"LOCOCOR\", \"CAUSABAS\", \"CIRCOBITO\"]]\n",
        "\n",
        "# Salva o CSV filtrado\n",
        "df.to_csv(\"SIM_2018_filtrado.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"✅ CSV salvo apenas com as colunas selecionadas!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22d21500-5d31-41eb-963b-3a8db5eadded",
        "id": "Azn_vY4DGK1O"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV salvo apenas com as colunas selecionadas!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ano 2019"
      ],
      "metadata": {
        "id": "jaZIZPoBGLP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definição do ano e estados\n",
        "\n",
        "estados = [\"AC\", \"AL\", \"AP\", \"AM\", \"BA\", \"CE\", \"DF\", \"ES\", \"GO\", \"MA\", \"MT\", \"MS\", \"MG\", \"PA\", \"PB\", \"PR\", \"PE\", \"PI\", \"RJ\", \"RN\", \"RS\", \"RO\", \"RR\", \"SC\", \"SP\", \"SE\", \"TO\"]\n",
        "anos = [2019]\n",
        "\n",
        "# Baixa os dados\n",
        "parquet_set = download(groups=\"CID10\", states=estados, years=anos)\n",
        "\n",
        "# Converte cada arquivo em df e adiciona colunas de estado e ano\n",
        "list_of_dfs = []\n",
        "for estado, parquet in zip(estados, parquet_set):\n",
        "    # Verifica se o objeto é válido antes de tentar converter\n",
        "    if parquet is not None and hasattr(parquet, 'to_dataframe'):\n",
        "        try:\n",
        "            df_estado = parquet.to_dataframe()\n",
        "            df_estado[\"ESTADO\"] = estado\n",
        "            df_estado[\"ANO\"] = 2019\n",
        "            list_of_dfs.append(df_estado)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Erro ao converter o arquivo do estado {estado} para DataFrame: {e}\")\n",
        "    else:\n",
        "        print(f\"⚠️ Objeto inválido encontrado para o estado: {estado}\")\n",
        "\n",
        "if list_of_dfs:\n",
        "    df = pd.concat(list_of_dfs, ignore_index=True)\n",
        "    print(\"✅ DF baixado com sucesso!!\")\n",
        "else:\n",
        "    print(\"❌ Nenhum DataFrame válido foi processado. Verifique os dados de entrada.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dca9267-2125-41f7-a251-2afe0ed21936",
        "id": "-sUAs3-wGLP_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "703873it [00:00, 93859519.91it/s]     \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ Erro ao converter o arquivo do estado AL para DataFrame: No objects to concatenate\n",
            "✅ DF baixado com sucesso!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtragem das colunas que não serão utilizadas\n",
        "Esta etapa foi feita antes de  colocar o df no bigquery devido ao tamanho da base de dados"
      ],
      "metadata": {
        "id": "GZrYUCWuGLQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleciona apenas as colunas desejadas\n",
        "df = df[[\"ESTADO\", \"ANO\", \"TIPOBITO\", \"IDADE\", \"SEXO\", \"RACACOR\",\"ESTCIV\", \"ESC2010\", \"LOCOCOR\", \"CAUSABAS\", \"CIRCOBITO\"]]\n",
        "\n",
        "# Salva o CSV filtrado\n",
        "df.to_csv(\"SIM_2019_filtrado.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"✅ CSV salvo apenas com as colunas selecionadas!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfc9c398-de15-409f-ffb0-f18c6583c924",
        "id": "NFqLhzIsGLQA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV salvo apenas com as colunas selecionadas!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ano 2020"
      ],
      "metadata": {
        "id": "7RBZBkGVGLlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definição do ano e estados\n",
        "\n",
        "estados = [\"AC\", \"AL\", \"AP\", \"AM\", \"BA\", \"CE\", \"DF\", \"ES\", \"GO\", \"MA\", \"MT\", \"MS\", \"MG\", \"PA\", \"PB\", \"PR\", \"PE\", \"PI\", \"RJ\", \"RN\", \"RS\", \"RO\", \"RR\", \"SC\", \"SP\", \"SE\", \"TO\"]\n",
        "anos = [2020]\n",
        "\n",
        "# Baixa os dados\n",
        "parquet_set = download(groups=\"CID10\", states=estados, years=anos)\n",
        "\n",
        "# Converte cada arquivo em df e adiciona colunas de estado e ano\n",
        "list_of_dfs = []\n",
        "for estado, parquet in zip(estados, parquet_set):\n",
        "    df_estado = parquet.to_dataframe()\n",
        "    df_estado[\"ESTADO\"] = estado\n",
        "    df_estado[\"ANO\"] = 2020\n",
        "    list_of_dfs.append(df_estado)\n",
        "\n",
        "# Concatena (junta) tudo\n",
        "df = pd.concat(list_of_dfs, ignore_index=True)\n",
        "print(\"✅ DF baixado com sucesso!!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef133d1b-16fe-4995-9584-f65b1b08677d",
        "id": "e4pA-yokGLlX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DOTO2020.parquet: 100%|██████████| 22.7k/22.7k [00:01<00:00, 19.9kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DF baixado com sucesso!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtragem das colunas que não serão utilizadas\n",
        "Esta etapa foi feita antes de  colocar o df no bigquery devido ao tamanho da base de dados"
      ],
      "metadata": {
        "id": "DAuAI-8pGLlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleciona apenas as colunas desejadas\n",
        "df = df[[\"ESTADO\", \"ANO\", \"TIPOBITO\", \"IDADE\", \"SEXO\", \"RACACOR\",\"ESTCIV\", \"ESC2010\", \"LOCOCOR\", \"CAUSABAS\", \"CIRCOBITO\"]]\n",
        "\n",
        "# Salva o CSV filtrado\n",
        "df.to_csv(\"SIM_2020_filtrado.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"✅ CSV salvo apenas com as colunas selecionadas!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3931dcba-fd22-4322-f5a3-3ec5d86ef572",
        "id": "QDBsKfoZGLlX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV salvo apenas com as colunas selecionadas!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ano 2021"
      ],
      "metadata": {
        "id": "9rHgMmvaGL40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definição do ano e estados\n",
        "\n",
        "estados = [\"AC\", \"AL\", \"AP\", \"AM\", \"BA\", \"CE\", \"DF\", \"ES\", \"GO\", \"MA\", \"MT\", \"MS\", \"MG\", \"PA\", \"PB\", \"PR\", \"PE\", \"PI\", \"RJ\", \"RN\", \"RS\", \"RO\", \"RR\", \"SC\", \"SP\", \"SE\", \"TO\"]\n",
        "anos = [2021]\n",
        "\n",
        "# Baixa os dados\n",
        "parquet_set = download(groups=\"CID10\", states=estados, years=anos)\n",
        "\n",
        "# Converte cada arquivo em df e adiciona colunas de estado e ano\n",
        "list_of_dfs = []\n",
        "for estado, parquet in zip(estados, parquet_set):\n",
        "    df_estado = parquet.to_dataframe()\n",
        "    df_estado[\"ESTADO\"] = estado\n",
        "    df_estado[\"ANO\"] = 2021\n",
        "    list_of_dfs.append(df_estado)\n",
        "\n",
        "# Concatena (junta) tudo\n",
        "df = pd.concat(list_of_dfs, ignore_index=True)\n",
        "print(\"✅ DF baixado com sucesso!!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b2982dd-41f5-487e-b58c-36e7a311b9ae",
        "id": "fVp-0u3jGL41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DOTO2021.parquet: 100%|██████████| 28.2k/28.2k [00:01<00:00, 14.3kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DF baixado com sucesso!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtragem das colunas que não serão utilizadas\n",
        "Esta etapa foi feita antes de  colocar o df no bigquery devido ao tamanho da base de dados"
      ],
      "metadata": {
        "id": "nsj1zlbvGL41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleciona apenas as colunas desejadas\n",
        "df = df[[\"ESTADO\", \"ANO\", \"TIPOBITO\", \"IDADE\", \"SEXO\", \"RACACOR\",\"ESTCIV\", \"ESC2010\", \"LOCOCOR\", \"CAUSABAS\", \"CIRCOBITO\"]]\n",
        "\n",
        "# Salva o CSV filtrado\n",
        "df.to_csv(\"SIM_2021_filtrado.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"✅ CSV salvo apenas com as colunas selecionadas!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22bec10a-f0aa-4418-cf25-e2e0abc1210c",
        "id": "j3Oafw9PGL41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV salvo apenas com as colunas selecionadas!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E3hc4XTBGL42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ano 2022"
      ],
      "metadata": {
        "id": "rQr_3-iHHc_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definição do ano e estados\n",
        "\n",
        "estados = [\"AC\", \"AL\", \"AP\", \"AM\", \"BA\", \"CE\", \"DF\", \"ES\", \"GO\", \"MA\", \"MT\", \"MS\", \"MG\", \"PA\", \"PB\", \"PR\", \"PE\", \"PI\", \"RJ\", \"RN\", \"RS\", \"RO\", \"RR\", \"SC\", \"SP\", \"SE\", \"TO\"]\n",
        "anos = [2022]\n",
        "\n",
        "# Baixa os dados\n",
        "parquet_set = download(groups=\"CID10\", states=estados, years=anos)\n",
        "\n",
        "# Converte cada arquivo em df e adiciona colunas de estado e ano\n",
        "list_of_dfs = []\n",
        "for estado, parquet in zip(estados, parquet_set):\n",
        "    df_estado = parquet.to_dataframe()\n",
        "    df_estado[\"ESTADO\"] = estado\n",
        "    df_estado[\"ANO\"] = 2022\n",
        "    list_of_dfs.append(df_estado)\n",
        "\n",
        "# Concatena (junta) tudo\n",
        "df = pd.concat(list_of_dfs, ignore_index=True)\n",
        "print(\"✅ DF baixado com sucesso!!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e25dd339-961e-4184-a17a-312bb04b1663",
        "id": "8wfxkfrCHc_R"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DOTO2022.parquet: 100%|██████████| 23.0k/23.0k [00:01<00:00, 14.2kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DF baixado com sucesso!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtragem das colunas que não serão utilizadas\n",
        "Esta etapa foi feita antes de  colocar o df no bigquery devido ao tamanho da base de dados"
      ],
      "metadata": {
        "id": "AJLVCMEoHc_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleciona apenas as colunas desejadas\n",
        "df = df[[\"ESTADO\", \"ANO\", \"TIPOBITO\", \"IDADE\", \"SEXO\", \"RACACOR\",\"ESTCIV\", \"ESC2010\", \"LOCOCOR\", \"CAUSABAS\", \"CIRCOBITO\"]]\n",
        "\n",
        "# Salva o CSV filtrado\n",
        "df.to_csv(\"SIM_2022_filtrado.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"✅ CSV salvo apenas com as colunas selecionadas!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "446adce8-494d-41e8-8fac-b55c3b820c7b",
        "id": "W4ZqOPdSHc_T"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV salvo apenas com as colunas selecionadas!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K5AnQhLFHc_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ano 2023"
      ],
      "metadata": {
        "id": "lrVVyZvfHiRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definição do ano e estados\n",
        "\n",
        "estados = [\"AC\", \"AL\", \"AP\", \"AM\", \"BA\", \"CE\", \"DF\", \"ES\", \"GO\", \"MA\", \"MT\", \"MS\", \"MG\", \"PA\", \"PB\", \"PR\", \"PE\", \"PI\", \"RJ\", \"RN\", \"RS\", \"RO\", \"RR\", \"SC\", \"SP\", \"SE\", \"TO\"]\n",
        "anos = [2023]\n",
        "\n",
        "# Baixa os dados\n",
        "parquet_set = download(groups=\"CID10\", states=estados, years=anos)\n",
        "\n",
        "# Converte cada arquivo em df e adiciona colunas de estado e ano\n",
        "list_of_dfs = []\n",
        "for estado, parquet in zip(estados, parquet_set):\n",
        "    df_estado = parquet.to_dataframe()\n",
        "    df_estado[\"ESTADO\"] = estado\n",
        "    df_estado[\"ANO\"] = 2023\n",
        "    list_of_dfs.append(df_estado)\n",
        "\n",
        "# Concatena (junta) tudo\n",
        "df = pd.concat(list_of_dfs, ignore_index=True)\n",
        "print(\"✅ DF baixado com sucesso!!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58321990-0fd0-484e-abfd-7a794062a02f",
        "id": "RTfTiLoHHiRn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DOTO2023.parquet: 100%|██████████| 21.8k/21.8k [00:01<00:00, 12.5kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DF baixado com sucesso!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtragem das colunas que não serão utilizadas\n",
        "Esta etapa foi feita antes de  colocar o df no bigquery devido ao tamanho da base de dados"
      ],
      "metadata": {
        "id": "9jWs8zoQHiRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleciona apenas as colunas desejadas\n",
        "df = df[[\"ESTADO\", \"ANO\", \"TIPOBITO\", \"IDADE\", \"SEXO\", \"RACACOR\",\"ESTCIV\", \"ESC2010\", \"LOCOCOR\", \"CAUSABAS\", \"CIRCOBITO\"]]\n",
        "\n",
        "# Salva o CSV filtrado\n",
        "df.to_csv(\"SIM_2023_filtrado.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"✅ CSV salvo apenas com as colunas selecionadas!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83eecec-8485-4311-e71b-769cc85fb693",
        "id": "Gbo4rAspHiRo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV salvo apenas com as colunas selecionadas!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Limpeza"
      ],
      "metadata": {
        "id": "paWpFODtvvrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "print(\"Iniciando o processo de unificação, filtragem e transformação dos arquivos CSV...\")\n",
        "\n",
        "# 1. Caminho da pasta onde esta os arquivos\n",
        "diretorio_dados = '/content/drive/MyDrive/csv_suicidio'\n",
        "\n",
        "# Lista de anos\n",
        "anos = range(2014, 2023) # De 2014 a 2023\n",
        "\n",
        "# Lsta para armazenar os DataFrames de cada ano\n",
        "df_list = []\n",
        "\n",
        "for ano in anos:\n",
        "    nome_arquivo = f'SIM_{ano}_filtrado.csv'\n",
        "    caminho_completo = os.path.join(diretorio_dados, nome_arquivo)\n",
        "\n",
        "    # Tenta ler o arquivo e adiciona à lista\n",
        "    try:\n",
        "        df_ano = pd.read_csv(caminho_completo)\n",
        "        df_list.append(df_ano)\n",
        "        print(f\"Arquivo {nome_arquivo} lido e adicionado à lista.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Aviso: O arquivo {nome_arquivo} não foi encontrado. Pulando para o próximo.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao ler o arquivo {nome_arquivo}: {e}\")\n",
        "\n",
        "# Concatena todos os dfs da lista em um só\n",
        "if df_list:\n",
        "    df_unificado = pd.concat(df_list, ignore_index=True)\n",
        "    print(\"Todos os DataFrames foram unificados com sucesso.\")\n",
        "else:\n",
        "    print(\"Nenhum arquivo foi encontrado. Verifique o caminho e os nomes dos arquivos.\")\n",
        "    raise Exception(\"Nenhum dado para processar.\")\n",
        "\n",
        "# 2. Aplicar os filtros nas linhas\n",
        "# Mantém apenas as linhas onde TIPOBITO e CIRCOBITO são 2\n",
        "df_final = df_unificado[\n",
        "    (df_unificado['TIPOBITO'] == 2) &\n",
        "    (df_unificado['CIRCOBITO'] == 2)\n",
        "].copy()\n",
        "\n",
        "df_final = df_final.dropna(subset=['ESTCIV', 'IDADE', 'TIPOBITO', 'ESC2010', 'CIRCOBITO'])\n",
        "\n",
        "print(\"Filtros aplicados. Total de linhas após o filtro:\", len(df_final))\n",
        "\n",
        "# 3. Transformar a coluna IDADE\n",
        "# Converte para string, remove o primeiro caractere e converte de volta para um número\n",
        "df_final['IDADE'] = pd.to_numeric(df_final['IDADE'].astype(str).str[1:], errors='coerce')\n",
        "\n",
        "\n",
        "# 4. Salvar o DataFrame final em um arquivo CSV\n",
        "nome_arquivo_final = 'SIM_UNIFICADO_FINAL.csv'\n",
        "caminho_salvar = os.path.join(diretorio_dados, nome_arquivo_final)\n",
        "df_final.to_csv(caminho_salvar, index=False)\n",
        "\n",
        "print(f\"\\nProcesso finalizado! O arquivo '{nome_arquivo_final}' foi salvo com sucesso.\")\n",
        "print(f\"O DataFrame final contém {df_final.shape[0]} linhas e {df_final.shape[1]} colunas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5lOnongvhSo",
        "outputId": "1abf438c-3ada-4146-f2d0-58d9899d1d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando o processo de unificação, filtragem e transformação dos arquivos CSV...\n",
            "Arquivo SIM_2014_filtrado.csv lido e adicionado à lista.\n",
            "Arquivo SIM_2015_filtrado.csv lido e adicionado à lista.\n",
            "Arquivo SIM_2016_filtrado.csv lido e adicionado à lista.\n",
            "Arquivo SIM_2017_filtrado.csv lido e adicionado à lista.\n",
            "Arquivo SIM_2018_filtrado.csv lido e adicionado à lista.\n",
            "Arquivo SIM_2019_filtrado.csv lido e adicionado à lista.\n",
            "Arquivo SIM_2020_filtrado.csv lido e adicionado à lista.\n",
            "Arquivo SIM_2021_filtrado.csv lido e adicionado à lista.\n",
            "Arquivo SIM_2022_filtrado.csv lido e adicionado à lista.\n",
            "Todos os DataFrames foram unificados com sucesso.\n",
            "Filtros aplicados. Total de linhas após o filtro: 103234\n",
            "\n",
            "Processo finalizado! O arquivo 'SIM_UNIFICADO_FINAL.csv' foi salvo com sucesso.\n",
            "O DataFrame final contém 103234 linhas e 11 colunas.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
